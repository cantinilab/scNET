{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the reproducibility of single-cell gene regulatory network inference algorithms\n",
    "\n",
    "scNET evaluates Gene Regulatory Network inference algorithms based on reproducibility.\n",
    "This markdown proposes a step by step tutorial for algorithm evaluation.\n",
    "\n",
    "Datasets used for this tutorial are available in the `scNET_data` directory, or the link https://cloud.biologie.ens.fr/index.php/s/JuJgrIL1jC6yZh4/download, as described in the Github README. Data preprocessing was done as described in the article.\n",
    "\n",
    "By default, this markdown performs reproducibility analysis for Human Retina data. The same analysis can be repeated on other biological contexts: CRC T-cells and 5 different types of hematopoietic cells by uncommenting its corresponding blocks of code in the `Loading pre-processed input scRNA-seq data` cells.\n",
    "\n",
    "# Setting the scNET environment\n",
    "\n",
    "Before loading data, make sure that the scNET environment has been correctly created and activated (see Github README). Additionally, run the following code to ensure an R interface with `jupyter notebook` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###interface with R\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load R functions from the scNET repository "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "###load reproducibility functions and libraries\n",
    "source('../scNET/Functions.R')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading pre-processed input scRNA-seq data \n",
    "\n",
    "As described in the methods of the paper, raw count data corresponding to QC passed cells (as per the original articles) was first downloaded and pre-processed. Here, data will be loaded as both Python and R variables, according to each algorithm's specificity (GRNBoost2 and GENIE3 in Python, PPCOR in R).\n",
    "\n",
    "In this cell, users can comment and uncomment lines depending on the biological context they'd like to analyze. The default is set to Human Retina data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "#RETINA\n",
    "files= glob.glob('../scNET_data/RETINA/*.csv')\n",
    "\n",
    "# #CRC T cells\n",
    "# files= glob.glob('../scNET_data/CRC T-cells/*.csv')\n",
    "\n",
    "# #Hematopoesis\n",
    "# files= glob.glob('../scNET_data/HEMATO/*CLP.csv')\n",
    "\n",
    "# files= glob.glob('../scNET_data/HEMATO/*DC.csv')\n",
    "\n",
    "# files= glob.glob('../scNET_data/HEMATO/*Ery.csv')\n",
    "\n",
    "# files= glob.glob('../scNET_data/HEMATO/*HSC.csv')\n",
    "\n",
    "# files= glob.glob('../scNET_data/HEMATO/*Mono.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the following cell will load the selected data to Python. Additionally, a list of Transcription Factors (TF) to provide to the algorithms GRNBoost2 and GENIE3 will also be loaded (see GRNBoost2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-301d6bcb5550>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#from arboreto.utils import load_tf_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mFirst_dataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mFirst_exp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mFirst_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mSecond_dataset\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "import pandas as pd\n",
    "from arboreto.utils import load_tf_names\n",
    "\n",
    "First_dataset= pd.read_csv(files[0], sep=',', index_col=0)\n",
    "First_exp= First_dataset.to_numpy()\n",
    "Second_dataset= pd.read_csv(files[1], sep=',', index_col=0)\n",
    "Second_exp= Second_dataset.to_numpy()\n",
    "genes= First_dataset.columns\n",
    "\n",
    "###Load TF list\n",
    "tf_names= load_tf_names('../scNET_data/TF_names.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell will load the same data into a R variable. Please make sure that the uncommented lines in this cell corresponds to the biological context selected in the first cell of this section. Again, the default is set to Human Retina data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in setwd(\"../scNET_data/RETINA/\") : \n",
      "  작업디렉토리를 변경할 수 없습니다\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "#RETINA\n",
    "setwd('../scNET_data/RETINA/')\n",
    "files= list.files(pattern='.csv')\n",
    "\n",
    "\n",
    "#CRC T-cells\n",
    "# setwd('../scNET_data/CRC T-cells')\n",
    "# files= list.files(pattern='.csv')\n",
    "\n",
    "# #Hematopoesis : CLP\n",
    "# setwd('../scNET_data/HEMATO')\n",
    "# files= list.files(pattern='CLP.csv')\n",
    "\n",
    "# files= list.files(pattern='DC.csv')\n",
    "\n",
    "# files= list.files(pattern='Ery.csv')\n",
    "\n",
    "# files= list.files(pattern='HSC.csv')\n",
    "\n",
    "# files= list.files(pattern='Mono.csv')\n",
    "\n",
    "\n",
    "###load files \n",
    "data= lapply(files, read.csv, row.names=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running single-cell network inference algorithms\n",
    "\n",
    "We will now apply GRNBoost2, GENIE3 and PPCOR to the loaded data.\n",
    "To apply any additional algorithms, refer to Github README\n",
    "\n",
    "## GRNBoost2\n",
    "\n",
    "GRNBoost2 (Aibar, S., et al., ) takes as input an expression matrix and produces a list of TF to target interactions. This link list is formatted into 3 columns (column 1: TF, column2: Target, column3: link weight), and represents a directed network. A curated list of human transcription factors(Chawla, K., et al.) is provided as input to steer the inference. The code to apply GRNBoost2 to this data has been configured as described in https://arboreto.readthedocs.io/en/latest/. To speed up computation and produce networks for both datasets at once, a custom Dask client will help paralellize tasks.  \n",
    "\n",
    "In practice, it is highly recommended to copy the following cell (preceded by the first two cells in the `Loading pre-processed input scRNA-seq data` section) into a seperate script and executing GRNBoost2 independantly, as the network inference is time consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Applying GRNBoost2###\n",
    "from arboreto.algo import grnboost2\n",
    "from distributed import LocalCluster, Client\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ex_matrix is a DataFrame with gene names as column names\n",
    "    #build local cluster for parallel computation \n",
    "    local_cluster = LocalCluster(n_workers=4,\n",
    "                                 threads_per_worker=1,\n",
    "                                 memory_limit=10e9)\n",
    "    custom_client = Client(local_cluster)\n",
    "    \n",
    "    #build networks \n",
    "    First_Network = grnboost2(expression_data=First_exp,\n",
    "                        gene_names= genes,\n",
    "                        tf_names= tf_names,\n",
    "                        client_or_address=custom_client,\n",
    "                        seed=100)\n",
    "    Second_Network = grnboost2(expression_data=Second_exp,\n",
    "                        gene_names= genes,\n",
    "                        tf_names= tf_names,\n",
    "                        client_or_address=custom_client,\n",
    "                        seed=100)\n",
    "    \n",
    "    #close custom client\n",
    "    custom_client.close()\n",
    "    local_cluster.close()\n",
    "    \n",
    "    #export networks to results file\n",
    "    \n",
    "    First_Network.to_csv('../scNet/Results/GRNBoost2_Network1.tsv', sep='\\t', index=False, header=False)\n",
    "    Second_Network.to_csv('../scNET/Results/GRNBoost2_Network2.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENIE3\n",
    "\n",
    "GENIE3 (Aibar, S., et al.) was also provided with a TF list, and produces a link list in the same format as GRNBoost2. Similarly, the code to apply GENIE3 has been configured as described in https://arboreto.readthedocs.io/en/latest/, and the inference is parallelized.  \n",
    "\n",
    "Again,it is highly recommended to copy the following cell (preceded by the first two cells in the `Loading pre-processed input scRNA-seq data` section) into a seperate script. This is especially pertinent because GENIE3 is  computationally heavier than GRNBoost2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Applying GENIE3###\n",
    "from arboreto.algo import genie3\n",
    "from distributed import LocalCluster, Client\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # ex_matrix is a DataFrame with gene names as column names\n",
    "    #build local cluster for parallel computation \n",
    "    local_cluster = LocalCluster(n_workers=4,\n",
    "                                 threads_per_worker=1,\n",
    "                                 memory_limit=10e9)\n",
    "    custom_client = Client(local_cluster)\n",
    "    \n",
    "    #build networks \n",
    "    First_Network = genie3(expression_data=First_exp,\n",
    "                        gene_names= genes,\n",
    "                        tf_names= tf_names,\n",
    "                        client_or_address=custom_client,\n",
    "                        seed=100)\n",
    "    Second_Network = genie3(expression_data=Second_exp,\n",
    "                        gene_names= genes,\n",
    "                        tf_names= tf_names,\n",
    "                        client_or_address=custom_client,\n",
    "                        seed=100)\n",
    "    \n",
    "    #close custom client\n",
    "    custom_client.close()\n",
    "    local_cluster.close()\n",
    "    \n",
    "    #export networks to results file\n",
    "    First_Network.to_csv('./scNet/Results/GENIE3_Network1.tsv', sep='\\t', index=False, header=False)\n",
    "    Second_Network.to_csv('./scNET/Results/GENIE3_Network2.tsv', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPCOR\n",
    "\n",
    "PPCOR calculates partial Spearman correlation coefficients between ALL possible gene pairs based on gene expression values. This algorithm produces an adjacency matrix, with genes in both columns and rows, and whose values correspond to correlation coefficients. A post-processing step is thus necessary for PPCOR results to 1) select interactions that are the most significant and 2) reformat links into a list that resembles GRNBoost2 and GENIE3 outputs. Note that PPCOR produces an undirected network after post-processing.\n",
    "\n",
    "Links are selected by setting a threshold on correlation coefficient values. The threshold is determined by calculating a significant correlation coefficent value, given a statistical power P=0.8, a significance level alpha=0.05, and N= the number of cells in the corresponding dataset.\n",
    "\n",
    "It was noted during the analysis that PPCOR can give non-valid correlation coefficient values (>1 and <-1). The post-processing function checks for the percentage of valid links in ppcor results. If coefficients are not in the expected range, no networks will be produced. For details on the post-processing code, see `Functions.R`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1] \"PPCOR_ RETINA _res.Rds\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "#Applying PPCOR \n",
    "library(ppcor)\n",
    "PPCOR.res.net1= pcor(data[[1]], method= 'spearman')\n",
    "PPCOR.res.net2= pcor(data[[2]], method= 'spearman')\n",
    "ppcor.res= list(net1= PPCOR.res.net1, net2=PPCOR.res.net2)\n",
    "\n",
    "setwd('../scNET/Results/')\n",
    "saveRDS(ppcor.res, file='PPCOR_raw_results.Rds')\n",
    "\n",
    "#calculate threhsold according to ncells in each dataset\n",
    "ncells1= nrow(data[[1]])#cells in rows\n",
    "thresh1=pwr.r.test(n = ncells1, sig.level = 0.05, power = 0.8, alternative = \"two.sided\")$r\n",
    "ncells2= nrow(data[[2]])#cells in rows\n",
    "thresh2=pwr.r.test(n = ncells2, sig.level = 0.05, power = 0.8, alternative = \"two.sided\")$r\n",
    "\n",
    "#Post-process PPCOR results to produce networks\n",
    "ppcor.net1=ppcor.post(ppcor.res[[1]], coefficient.threshold = thresh1)\n",
    "ppcor.net2=ppcor.post(ppcor.res[[2]], coefficient.threshold = thresh2)\n",
    "\n",
    "#Export PPCOR results\n",
    "if(nrow(ppcor.net1)!= 0 & nrow(ppcor.net2)!=0){\n",
    "    write.csv(ppcor.net1, 'PPCOR_Network1.tsv', quote=F, sep='\\t')\n",
    "    write.csv(ppcor.net2, 'PPCOR_Network2.tsv', quote=F, sep='\\t')\n",
    "}else{message('Networks produced by PPCOR can not be analysed for reproducibility')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GeneNet\n",
    "\n",
    "GeneNet first converts a correlation network into a partial correlation graph through the R function 'ggm.estimate.pcor()'. Subsequently, a partial ordering of the nodes is established by multiple testing of the log-ratio of standardized partial variances with functions 'network.test.edges()' and 'extract.network()'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#Applying GeneNet\n",
    "library(GeneNet)\n",
    "data1.pc = ggm.estimate.pcor(data[[1]])\n",
    "data1.edges = network.test.edges(data1.pc, direct=TRUE, fdr=TRUE)\n",
    "data1.net = extract.network(data1.edges )\n",
    "\n",
    "data2.pc= ggm.estimate.pcor(data[[2]])\n",
    "data2.edges = network.test.edges(data2.pc, direct=TRUE, fdr=TRUE)\n",
    "data2.net = extract.network(data2.edges)\n",
    "\n",
    "#renaming links\n",
    "nodes= colnames(data[[1]])\n",
    "transfo1= transform.node.labels(data1.net, nodes)\n",
    "transfo2= transform.node.labels(data2.net, nodes)\n",
    "\n",
    "#reassign weights\n",
    "GeneNet.res1= cbind(transfo1, data1.net[,1])\n",
    "GeneNet.res2= cbind(transfo2, data2.net[,1])\n",
    "\n",
    "#Export result files to \n",
    "write.csv(GeneNet.res1,'GeneNet_Network1.tsv', quote=F, sep='\\t')\n",
    "write.csv(GeneNet.res2,'GeneNet_Network2.tsv', quote=F, sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLR\n",
    "\n",
    "The Context Likelihood of Relatedness (CLR) approach first computes mutual information value between all possible gene pairs. Then the algorithm adjusts the link weights by using the background distribution of mutual information (MI) values as a reference. This allows the algorithm to filter out false postive gene links.\n",
    "\n",
    "This algorithm can be used by loading the R package minet (Mutual Information NETworks). The 'build.mim' function takes as input an expression matrix purged of all zero counts and computes a mutual information matrix (MIM), an adjacency matrix of all mutual information values. The 'clr' function takes this MIM as input and completes the inference process.\n",
    "\n",
    "However, since the data has not yet been purged of zero counts, the function 'remove.zero.counts' included in  functions.R will remove any genes that have a zero count in any cells from the original expression matrix before computing mutual information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#load minet library\n",
    "library(minet)\n",
    "\n",
    "#remove genes with zero counts\n",
    "new1= remove.zero.count(data[[1]])\n",
    "new2= remove.zero.count(data[[2]])\n",
    "\n",
    "##check number of removed genes\n",
    "ncol(net1)- ncol(new1)\n",
    "ncol(net2)- ncol(new2)\n",
    "\n",
    "##Apply CLR\n",
    "net1.mim= build.mim(new1, estimator = 'spearman', disc = 'none')\n",
    "net2.mim= build.mim(new2, estimator = 'spearman', disc = 'none')\n",
    "\n",
    "net1.clr= clr(net1.mim)\n",
    "net2.clr= clr(net2.mim)\n",
    "\n",
    "#Save result networks\n",
    "clr1=BuildNetworks(net1.clr)\n",
    "clr2=BuildNetworks(net2.clr)\n",
    "\n",
    "write.csv(clr1,'CLR_Network1.tsv', quote=F, sep='\\t')\n",
    "write.csv(clr2,'CLR_Network2.tsv', quote=F, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Custom algorithm comparison\n",
    "\n",
    "It is possible to test any other single cell gene network inference algorithms for reproducibility using the measures that we have developped. Just make sure to use two independant expression matrices as input, as shown above. Also, the networks inferred with these algorithms must be formatted as a dataframe with 3 columns (column 1 = gene 1, column 2= gene 2, and column 3= link weights). It is also important to check if the network is directed or not- whether or not the gene to gene interaction has an explicit direction (gene 1 regulates gene 2, for example)- and adjust the 'Directed' variable accordingly when proceeding with this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering networks\n",
    "\n",
    "Due to the various methods used to infer networks, the obtained networks can vary greatly in size, from a few thousand links to a few million. This is why we chose to determine a maximum number of links to be analyzed, called k. If the number of links to analyze in a certain network is lower than k, the full network will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#determine k\n",
    "k= 100000\n",
    "\n",
    "#select block of code corresponding to the networks to load. Comment out all others\n",
    "setwd('../scNET/Results/')\n",
    "\n",
    "net1= read.table('GRNBoost2_Network1.tsv', quote=F)\n",
    "net2= read.table('GRNBoost2_Network2.tsv', quote=F)\n",
    "\n",
    "# net1= read.table('GENIE3_Network1.tsv', quote=F)\n",
    "# net2= read.table('GENIE3_Network2.tsv', quote=F)\n",
    "\n",
    "# net1= read.table('PPCOR_Network1.tsv', quote=F)\n",
    "# net2= read.table('PPCOR_Network2.tsv', quote=F)\n",
    "\n",
    "# net1= read.table('GeneNet_Network1.tsv', quote=F)\n",
    "# net2= read.table('GeneNet_Network2.tsv', quote=F)\n",
    "\n",
    "# net1= read.table('CLR_Network1.tsv', quote=F)\n",
    "# net2= read.table('CLR_Network2.tsv', quote=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm reproducibility evaluation\n",
    "\n",
    "Once all algorithms have been applied on both datasets, their reproducibility can be evaluated. Three metrics are calculated: Intersection index, Weighted Jaccard Similarity (WJS) and RcisTarget score (see Methods for more details, and `Functions.R` for details on the code). \n",
    "\n",
    "Before calculating the RcisTarget score, the RcisTarget algorithm(Aibar, S., et al.) must first be applied to all networks. Note that here, RcisTarget has been customized to select only High Confidence links, that are supported by strong motif evidence (see Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "#execute Rcistarget\n",
    "setwd('../scNET/')\n",
    "\n",
    "Rcis_GRNBoost2 = Custom.Rcis(input.dir='scNET/Results',\n",
    "                     pattern='GRNBoost2',\n",
    "                     chosenDb=\"hg19-tss-centered-5kb-7species.mc9nr.feather\",\n",
    "                     output.dir='scNET/Results',\n",
    "                     MinGenesetSize=0, \n",
    "                     directed=T)\n",
    "\n",
    "Rcis_GENIE3 = Custom.Rcis(input.dir='scNET/Results',\n",
    "                     pattern='GENIE3',\n",
    "                     chosenDb=\"hg19-tss-centered-5kb-7species.mc9nr.feather\",\n",
    "                     output.dir='scNET/Results',\n",
    "                     MinGenesetSize=0, \n",
    "                     directed=T)\n",
    "\n",
    "Rcis_PPCOR = Custom.Rcis(input.dir='scNET/Results',\n",
    "                     pattern='PPCOR',\n",
    "                     chosenDb=\"hg19-tss-centered-5kb-7species.mc9nr.feather\",\n",
    "                     output.dir='scNET/Results',\n",
    "                     MinGenesetSize=0, \n",
    "                     directed=F)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once RcisTarget has been applied, we can now calculate reproducibility scores for each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "###Results\n",
    "Results= Reproducibility.stats(c('GRNBoost2*.tsv','GENIE3*.tsv', 'PPCOR*.tsv'),\n",
    "                               Results.dir= 'scNET/Results')\n",
    "\n",
    "Results[,'RcisTarget_index']= c(Rcis.percent(Rcis_GRNBoost2),\n",
    "                               Rcis.percent(Rcis_GENIE3),\n",
    "                               Rcis.percent(Rcis_PPCOR))\n",
    "\n",
    "Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results can be visualized as barplots, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "###Plotting results\n",
    "\n",
    "ggplot(data=Results, aes(x=Algorithm, y= Intersection_index, fill='')) +\n",
    "geom_bar(stat=\"identity\")+\n",
    "ggtitle('Intersection index comparison')\n",
    "\n",
    "ggplot(data=Results, aes(x=Algorithm, y= WJS, fill='')) +\n",
    "geom_bar(stat=\"identity\")+\n",
    "ggtitle('WJS comparison')\n",
    "\n",
    "ggplot(data=Results, aes(x=Algorithm, y= RcisTarget_index, fill='')) +\n",
    "geom_bar(stat=\"identity\")+\n",
    "ggtitle('RcisTarget score comparison')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantile cutting\n",
    "\n",
    "In this part of the analysis, we threshold network weights according to certain percentiles (40, 80 and 90%). Calculating reproducibility measures for each percentile allows us to compare algorithm stability (see Methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "###Quantile Cutting\n",
    "GRN= lapply(list.files(pattern='GRNBoost2*.tsv'), read.table)\n",
    "GEN= lapply(list.files(pattern='GENIE3*.tsv'), read.table)\n",
    "PPCOR= lapply(list.files(pattern='PPCOR*.tsv'), read.table)\n",
    "\n",
    "thresh.GRN=quantile.stats(GRN[[1]], GRN[[2]], c(0.4, 0.8, 0.9), Directed=T, label='GRNBoost2')\n",
    "thresh.GEN=quantile.stats(GEN[[1]], GEN[[2]], c(0.4, 0.8, 0.9), Directed=T, label='GENIE3')\n",
    "thresh.PPCOR=quantile.stats(PPCOR[[1]], PPCOR[[2]], c(0.4, 0.8, 0.9), Directed=F, label='PPCOR')\n",
    "\n",
    "all.quantiles= rbind(thresh.GRN, thresh.GEN)\n",
    "all.quantiles= rbind(all.quantiles, thresh.PPCOR)\n",
    "\n",
    "all.quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above results can be visualized, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "###Plots\n",
    "ggplot(data=all.quantiles, aes(x=Quantile, y= intersection, group=Algorithm)) +\n",
    "  geom_line(aes(color=Algorithm))+\n",
    "  geom_point(aes(color=Algorithm))+\n",
    "  ggtitle('Intersection Index comparison according to Quantiles')\n",
    "\n",
    "ggplot(data=all.quantiles, aes(x=Quantile, y= WJS, group=Algorithm)) +\n",
    "  geom_line(aes(color=Algorithm))+\n",
    "  geom_point(aes(color=Algorithm))+\n",
    "  ggtitle('WJS comparison according to Quantiles')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
